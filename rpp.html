<html>
<head>
<style>
body {
margin:0px;
padding:0px;
width:  100%;
height: 100%;
background-color:black
}
</style>
</head>
<body>
<canvas id="canvas"></canvas>
<script type="text/javascript">
	var width = window.innerWidth;
	var height = window.innerHeight;

	canvas.width  = width;
	canvas.height = height;
    if (! window.AudioContext) {
        if (! window.webkitAudioContext) {
            alert('no audiocontext found');
        }
        window.AudioContext = window.webkitAudioContext;
    }
    var context = new AudioContext();
    var audioBuffer;
    var sourceNode;
    var analyser;
    var javascriptNode;

    // get the context from the canvas to draw on
    var ctx = document.getElementById("canvas").getContext("2d");

    // create a gradient for the fill. Note the strange
    // offset, since the gradient is calculated based on
    // the canvas, not the specific element we draw
    var gradient = ctx.createLinearGradient(0,0,0,height/2);
    gradient.addColorStop(0,'#aac8de');
	gradient.addColorStop(0.25,'#44a1e2');
    gradient.addColorStop(0.75,'#0d83d5');
    gradient.addColorStop(1,'#005a99');


    // load the sound
    setupAudioNodes();
    loadSound("audio/Alan Walker - Fade [NCS Release].mp3");


    function setupAudioNodes() {

        // setup a javascript node
        javascriptNode = context.createScriptProcessor(2048, 1, 1);
        // connect to destination, else it isn't called
        javascriptNode.connect(context.destination);


        // setup a analyzer
        analyser = context.createAnalyser();
        analyser.smoothingTimeConstant = 0.4;
        analyser.fftSize = 1024;

        // create a buffer source node
        sourceNode = context.createBufferSource();
        sourceNode.connect(analyser);
        analyser.connect(javascriptNode);

        sourceNode.connect(context.destination);
    }

    // load the specified sound
    function loadSound(url) {
        var request = new XMLHttpRequest();
        request.open('GET', url, true);
        request.responseType = 'arraybuffer';

        // When loaded decode the data
        request.onload = function() {

            // decode the data
            context.decodeAudioData(request.response, function(buffer) {
                // when the audio is decoded play the sound
                playSound(buffer);
            }, onError);
        }
        request.send();
    }


    function playSound(buffer) {
        sourceNode.buffer = buffer;
        sourceNode.start(0);
    }

    // log if an error occurs
    function onError(e) {
        console.log(e);
    }

    // when the javascript node is called
    // we use information from the analyzer node
    // to draw the volume
    javascriptNode.onaudioprocess = function() {

        // get the average for the first channel
        var array =  new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(array);

        // clear the current state
        ctx.clearRect(0, 0, width, height);


        drawSpectrum(array);

    }


    function drawSpectrum(array) {
        for ( var i = 0; i < (array.length); i++ ){
            var value = array[i];
			// set the fill style
			ctx.fillStyle=gradient;
            ctx.fillRect(i*4,(height/2)-value,3,height/2-((height/2)-value));
			ctx.fillStyle="#323232";
			ctx.fillRect(i*4,height/2,3,value);
            //  console.log([i,value])
        }
    };

</script>
</body>